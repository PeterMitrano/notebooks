{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.set_printoptions(suppress=True, precision=2)\n",
    "import scipy.optimize as optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define goal\n",
    "\n",
    "Our goal will be denoted as $g$, for now we simply assume its defined in the full state space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = np.array([[5], [0], [6], [0], [7], [0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Initial Data\n",
    "\n",
    "Let's pretend our data comes from pulling a 2-link object to the right for 6 time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "for _ in range(100):\n",
    "    y = 0 #np.random.randint(-10,10)\n",
    "    i = np.random.randint(-5,5)\n",
    "    training_data.append((np.array([[i],[y],[i+1],[y],[i+2],[y]]),\n",
    "         np.array([[1],[0]]),\n",
    "         np.array([[i+1],[y],[i+2],[y],[i+3],[y]]),\n",
    "         np.array([[g[0] - i]]),\n",
    "         np.array([[g[0] - i+1]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize Simple Models\n",
    "\n",
    "We assume linear forms for all our functions:\n",
    "$\n",
    "\\begin{align}\n",
    "f(s_t) &= As_t \\\\\n",
    "f(s_t) &= Bo_t + Cu_t \\\\\n",
    "\\hat{c}(s_t) &= D(Ag - As_t) = D(Ag - o_t)\\\\\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def params_to_matrices(params):\n",
    "    a1 = params[0]\n",
    "    a2 = params[1]\n",
    "    a3 = params[2]\n",
    "    a4 = params[3]\n",
    "    a5 = params[4]\n",
    "    a6 = params[5]\n",
    "    b = params[6]\n",
    "    c1 = params[7]\n",
    "    c2 = params[8]\n",
    "    d = params[9]\n",
    "\n",
    "    A = np.array([[a1, a2, a3, a4, a5, a6]])\n",
    "    B = np.array([[b]])\n",
    "    C = np.array([[c1, c2]])\n",
    "    D = np.array([[d]])\n",
    "    return A, B, C, D\n",
    "\n",
    "def latent_prediction_objective(params, data, alpha=0.5, regularization=0):\n",
    "    \"\"\" return: MSE over all training examples \"\"\"\n",
    "    A, B, C, D = params_to_matrices(params)\n",
    "\n",
    "    err = np.zeros(len(data))\n",
    "    for i, (s, u, s_, c, c_) in enumerate(data):\n",
    "        o = A@s\n",
    "        o_ = A@s_\n",
    "        o_g = A@g\n",
    "        err[i] = alpha*np.linalg.norm(o + (B@o + C@u) - o_) + (1-alpha)*abs(D@(o_g-o) - c) + regularization * np.linalg.norm(A)\n",
    "\n",
    "    obj = (err**2).mean()\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(training_data, objective_func, **kwargs):\n",
    "    \"\"\"\n",
    "    param training_data: a list of tuples ([6x1], [2x1], [6x1], [1x1])\n",
    "    \"\"\"\n",
    "        \n",
    "    def __objective(params):\n",
    "        return objective_func(params, training_data, **kwargs)\n",
    "    \n",
    "    initial_params = np.random.randn(10)\n",
    "    for i in range(10):\n",
    "        result = optimize.minimize(__objective, initial_params, method='Powell')\n",
    "        if result.success:\n",
    "            break\n",
    "    \n",
    "    if not result.success:\n",
    "        print(\"Status: {:d}, Message: {:s}\".format(result.status, result.message))\n",
    "        return None\n",
    "    print('Finished in {:d} iterations'.format(result.nit))\n",
    "    return result.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Objective Function\n",
    "\n",
    "To double check my objective function, let's make sure that my hand-designed model reductions give zero in the objective function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for hand-designed good params: 0.0\n",
      "loss for hand-designed bad params: 18.7525\n"
     ]
    }
   ],
   "source": [
    "my_params = np.array([1, 0, 0, 0, 0, 0, 0, 1, 0, 1])\n",
    "print(\"loss for hand-designed good params:\", latent_prediction_objective(my_params, data=training_data, alpha=0.5))\n",
    "\n",
    "my_params = np.array([0, 1, 0, 0, 0, 0, 0, 1, 0, 1])\n",
    "print(\"loss for hand-designed bad params:\", latent_prediction_objective(my_params, data=training_data, alpha=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 7 iterations\n"
     ]
    }
   ],
   "source": [
    "params = train(training_data, latent_prediction_objective, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective Cost/Loss: 1.030034520278715e-22\n",
      "Model reduction Matrix: [[ 0.05  1.01 -2.26 -0.26 -0.41 -0.75]]\n",
      "Dynamics Matrix: [[0.]] , [[-2.63 18.44]]\n",
      "Cost Matrix: [[-0.38]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Objective Cost/Loss:\", latent_prediction_objective(params, training_data, alpha=0.5))\n",
    "A, B, C, D = params_to_matrices(params)\n",
    "print(\"Model reduction Matrix:\", A)\n",
    "print(\"Dynamics Matrix:\", B, ',', C)\n",
    "print(\"Cost Matrix:\", D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can now perfectly predict future latent state and cost\n",
    "\n",
    "Consider what happens if we follow a plan of pulling right from the origin\n",
    "What is the predicted cost of the plan $[[1,0], \\dots]$ ? In the real world, the sum of cost at each state is $5+4+3+2+1=15$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15.]]\n"
     ]
    }
   ],
   "source": [
    "actions = [np.array([[1],[0]]), np.array([[1],[0]]),np.array([[1],[0]]),np.array([[1],[0]]),np.array([[1],[0]])]\n",
    "s0 = np.array([[0], [0], [1], [0], [2], [0]])\n",
    "o = A@s0\n",
    "predicted_total_cost = 0\n",
    "for i, u in enumerate(actions):\n",
    "    o_ = o + B@o + C@u\n",
    "    c_hat = D@(A@g - o)\n",
    "    predicted_total_cost += c_hat\n",
    "    o = o_\n",
    "print(predicted_total_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok great! **We can perfectly predict the future latent state and cost!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What if we only consider cost, and predicting cost?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_step_cost_prediction_objective(params, data, alpha=0.5, regularization=0):\n",
    "    \"\"\" return: MSE over all training examples \"\"\"\n",
    "    A, B, C, D = params_to_matrices(params)\n",
    "    \n",
    "    def _cost(_o):\n",
    "            return D@(o_g - _o)\n",
    "\n",
    "    err = np.zeros(len(data))\n",
    "    for i, (s, u, s_, c, c_) in enumerate(data):\n",
    "        o = A@s\n",
    "        o_ = A@s_\n",
    "        o_g = A@g\n",
    "        predicted_o_  = o + B@o + C@u\n",
    "        one_step_predicted_cost_accuracy = np.linalg.norm(_cost(predicted_o_) - _cost(o_))\n",
    "        current_cost_accuracy = abs(_cost(o) - c)\n",
    "        err[i] = (1-alpha)*current_cost_accuracy + alpha * one_step_predicted_cost_accuracy + regularization * np.linalg.norm(A)\n",
    "        \n",
    "    obj = (err**2).mean()\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for hand-designed good params: 0.0\n",
      "loss for hand-designed bad params: 18.7525\n"
     ]
    }
   ],
   "source": [
    "my_params = np.array([1, 0, 0, 0, 0, 0, 0, 1, 0, 1])\n",
    "print(\"loss for hand-designed good params:\",\n",
    "      one_step_cost_prediction_objective(my_params, data=training_data, alpha=0.5))\n",
    "\n",
    "my_params = np.array([0, 1, 0, 0, 0, 0, 0, 1, 0, 1])\n",
    "print(\"loss for hand-designed bad params:\",\n",
    "      one_step_cost_prediction_objective(my_params, data=training_data, alpha=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 7 iterations\n"
     ]
    }
   ],
   "source": [
    "params = train(training_data, one_step_cost_prediction_objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Objective: 9.841737428322009e-23\n",
      "Cost-Only Objective: 9.825558328280835e-23\n",
      "Model reduction Matrix: [[-0.54 -0.14 -0.06  0.01  1.61  0.14]]\n",
      "Dynamics Matrix: [[-0.]] , [[ 1.01 21.36]]\n",
      "Cost Matrix: [[0.99]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction Objective:\", latent_prediction_objective(params, training_data, alpha=0.5))\n",
    "print(\"Cost-Only Objective:\", one_step_cost_prediction_objective(params, training_data, alpha=0.5))\n",
    "A, B, C, D = params_to_matrices(params)\n",
    "print(\"Model reduction Matrix:\", A)\n",
    "print(\"Dynamics Matrix:\", B, ',', C)\n",
    "print(\"Cost Matrix:\", D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly, we are also able to fit our data in this case. Much more interestingly, **We also get latent state prediction accuracy for free, just by predicting in cost!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What if the data is more diverse?\n",
    "\n",
    "What if we include various y values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "for _ in range(100):\n",
    "    y = np.random.randint(-10,10)\n",
    "    i = np.random.randint(-5,5)\n",
    "    training_data.append((np.array([[i],[y],[i+1],[y],[i+2],[y]]),\n",
    "         np.array([[1],[0]]),\n",
    "         np.array([[i+1],[y],[i+2],[y],[i+3],[y]]),\n",
    "         np.array([[g[0] - i]]),\n",
    "         np.array([[g[0] - i+1]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for hand-designed good params: 0.0\n",
      "loss for hand-designed bad params: 16.54\n"
     ]
    }
   ],
   "source": [
    "my_params = np.array([1, 0, 0, 0, 0, 0, 0, 1, 0, 1])\n",
    "print(\"loss for hand-designed good params:\", latent_prediction_objective(my_params, data=training_data, alpha=0.5))\n",
    "\n",
    "my_params = np.array([0, 1, 0, 0, 0, 0, 0, 1, 0, 1])\n",
    "print(\"loss for hand-designed bad params:\", latent_prediction_objective(my_params, data=training_data, alpha=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 6 iterations\n"
     ]
    }
   ],
   "source": [
    "params = train(training_data, latent_prediction_objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective Cost/Loss: 2.3064113713282737e-22\n",
      "Model reduction Matrix: [[-4.   -1.9   3.06 -0.55 -0.13  2.45]]\n",
      "Dynamics Matrix: [[0.]] , [[-1.07 17.74]]\n",
      "Cost Matrix: [[-0.93]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Objective Cost/Loss:\", latent_prediction_objective(params, training_data, alpha=0.5))\n",
    "A, B, C, D = params_to_matrices(params)\n",
    "print(\"Model reduction Matrix:\", A)\n",
    "print(\"Dynamics Matrix:\", B, ',', C)\n",
    "print(\"Cost Matrix:\", D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yup, still works. Although this data is not realistic to the motion of the links. This just shows that if we add a distractor variable which does not help explain the cost, we can still \"ignore it\". Specifically, the B matrix (just a real number here) is still 0 and the y components of the model reduction can be arbitrary values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3064113713282737e-22\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.3064113713282737e-22"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shows that the parameters in the y components don't matter\n",
    "test_params = np.array([[-1.81, -100, .24, 100, .26, 0]])\n",
    "print(latent_prediction_objective(params, training_data))\n",
    "test_params = np.array([[-1.81, 0, .24, -100, .26, 1000]])\n",
    "latent_prediction_objective(params, training_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since they don't matter, do we want to consider enforcing that the norm of the model reduction vector is minimized?\n",
    "\n",
    "# Add Regularization to the Model Reduction Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 4 iterations\n",
      "Objective Cost/Loss: 3.956812237944807e-17\n",
      "Model reduction Matrix: [[-0.46 -0.7  -0.09  0.59  1.07  0.12]]\n",
      "Dynamics Matrix: [[0.]] , [[ 0.52 14.24]]\n",
      "Cost Matrix: [[1.91]]\n"
     ]
    }
   ],
   "source": [
    "params = train(training_data, latent_prediction_objective, regularization=2)\n",
    "print(\"Objective Cost/Loss:\", latent_prediction_objective(params, training_data, alpha=0.5))\n",
    "A, B, C, D = params_to_matrices(params)\n",
    "print(\"Model reduction Matrix:\", A)\n",
    "print(\"Dynamics Matrix:\", B, ',', C)\n",
    "print(\"Cost Matrix:\", D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This doesn't work like I expected... I don't think this is a great idea."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
