{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy Problem Optimization\n",
    "\n",
    "This notebook explores what happens when you take the two-link rope toy problem and pull the rope to the right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'toy_problem_optimization_common'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b6bcd56f21f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtoy_problem_optimization_common\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named 'toy_problem_optimization_common'"
     ]
    }
   ],
   "source": [
    "import toy_problem_optimization_common"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define goal\n",
    "\n",
    "Our goal will be denoted as $g$, for now we simply assume its defined in the full state space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g = np.array([[5], [0], [6], [0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Data\n",
    "\n",
    "Let's pretend our data comes from pulling a 2-link object to the right for 6 time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "manual_data = []\n",
    "for _ in range(100):\n",
    "    y = 0 #np.random.randint(-10,10)\n",
    "    i = np.random.randint(-5,5)\n",
    "    # Training data looks like [(s_t, u_t, s_{t+1}, c_t, c_{t+1})]\n",
    "    manual_data.append((np.array([[i],[y],[i+1],[y]]),\n",
    "         np.array([[1],[0]]),\n",
    "         np.array([[i+1],[y],[i+2],[y]]),\n",
    "         np.array([[(g[0] - i)**2]]),\n",
    "         np.array([[(g[0] - i+1)**2]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How well do Random Parameters Do (on average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median cost for random parameters 729.557\n"
     ]
    }
   ],
   "source": [
    "N = 1000\n",
    "costs = np.zeros(N)\n",
    "for i in range(N):\n",
    "    random_params = np.random.randn(8)\n",
    "    costs[i] = latent_prediction_objective(random_params, data=manual_data, alpha=0.5)\n",
    "print(\"Median cost for random parameters {:.3f}\".format(np.median(costs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Objective Function\n",
    "\n",
    "To double check my objective function, let's make sure that my hand-designed model reductions give zero in the objective function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for hand-designed good params: 0.0\n",
      "loss for hand-designed bad params: 623.2375\n"
     ]
    }
   ],
   "source": [
    "my_params = np.array([1, 0, 0, 0, 0, 1, 0, 1])\n",
    "print(\"loss for hand-designed good params:\", latent_prediction_objective(my_params, data=manual_data, alpha=0.5))\n",
    "\n",
    "my_params = np.array([0, 1, 0, 0, 0, 1, 0, 1])\n",
    "print(\"loss for hand-designed bad params:\", latent_prediction_objective(my_params, data=manual_data, alpha=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 5 iterations\n"
     ]
    }
   ],
   "source": [
    "params = train(manual_data, latent_prediction_objective, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective Cost/Loss: 4.281324573080723e-25\n",
      "Model reduction Matrix: [[ 0.03 13.3   0.04 12.62]]\n",
      "Dynamics Matrix: [[-0.]] , [[ 0.06 12.91]]\n",
      "Cost Matrix: [[244.77]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Objective Cost/Loss:\", latent_prediction_objective(params, manual_data, alpha=0.5))\n",
    "A, B, C, D = params_to_matrices(params)\n",
    "print(\"Model reduction Matrix:\", A)\n",
    "print(\"Dynamics Matrix:\", B, ',', C)\n",
    "print(\"Cost Matrix:\", D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can now perfectly predict future latent state and cost\n",
    "\n",
    "Consider what happens if we follow a plan of pulling right from the origin\n",
    "What is the predicted cost of the plan $[[1,0], \\dots]$ ? In the real world, the sum of cost at each state is $5^2+4^2+3^2+2^2+1^2=55$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[55.]]\n"
     ]
    }
   ],
   "source": [
    "actions = [np.array([[1],[0]]), np.array([[1],[0]]),np.array([[1],[0]]),np.array([[1],[0]]),np.array([[1],[0]])]\n",
    "s0 = np.array([[0], [0], [1], [0]])\n",
    "o = A@s0\n",
    "predicted_total_cost = 0\n",
    "for i, u in enumerate(actions):\n",
    "    o_ = o + B@o + C@u\n",
    "    c_hat = (A@g - o).T@D@(A@g - o)\n",
    "    predicted_total_cost += c_hat\n",
    "    o = o_\n",
    "print(predicted_total_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok great! **We can perfectly predict the future latent state and cost!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if we only consider cost, and predicting cost?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for hand-designed good params: 0.0\n",
      "loss for hand-designed bad params: 623.2375\n"
     ]
    }
   ],
   "source": [
    "my_params = np.array([1, 0, 0, 0, 0, 1, 0, 1])\n",
    "print(\"loss for hand-designed good params:\",\n",
    "      one_step_cost_prediction_objective(my_params, data=manual_data, alpha=0.5))\n",
    "\n",
    "my_params = np.array([0, 1, 0, 0, 0, 1, 0, 1])\n",
    "print(\"loss for hand-designed bad params:\",\n",
    "      one_step_cost_prediction_objective(my_params, data=manual_data, alpha=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 8 iterations\n"
     ]
    }
   ],
   "source": [
    "params = train(manual_data, one_step_cost_prediction_objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Objective: 1.5213205860939539e-27\n",
      "Cost-Only Objective: 3.2808697006601915e-27\n",
      "Model reduction Matrix: [[   0.22 5324.04   -0.22 5322.36]]\n",
      "Dynamics Matrix: [[-0.]] , [[  -0.   5323.29]]\n",
      "Cost Matrix: [[171375.06]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction Objective:\", latent_prediction_objective(params, manual_data, alpha=0.5))\n",
    "print(\"Cost-Only Objective:\", one_step_cost_prediction_objective(params, manual_data, alpha=0.5))\n",
    "A, B, C, D = params_to_matrices(params)\n",
    "print(\"Model reduction Matrix:\", A)\n",
    "print(\"Dynamics Matrix:\", B, ',', C)\n",
    "print(\"Cost Matrix:\", D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly, we are also able to fit our data in this case. Much more interestingly, **We also get latent state prediction accuracy for free, just by predicting in cost!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What if the data is more diverse?\n",
    "\n",
    "What if we include various y values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "manual_data = []\n",
    "for _ in range(100):\n",
    "    y = np.random.randint(-10,10)\n",
    "    i = np.random.randint(-5,5)\n",
    "    manual_data.append((np.array([[i],[y],[i+1],[y]]),\n",
    "         np.array([[1],[0]]),\n",
    "         np.array([[i+1],[y],[i+2],[y]]),\n",
    "         np.array([[(g[0] - i)**2]]),\n",
    "         np.array([[(g[0] - i+1)**2]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for hand-designed good params: 0.0\n",
      "loss for hand-designed bad params: 465.9475\n"
     ]
    }
   ],
   "source": [
    "my_params = np.array([1, 0, 0, 0, 0, 1, 0, 1])\n",
    "print(\"loss for hand-designed good params:\", latent_prediction_objective(my_params, data=manual_data, alpha=0.5))\n",
    "\n",
    "my_params = np.array([0, 1, 0, 0, 0, 1, 0, 1])\n",
    "print(\"loss for hand-designed bad params:\", latent_prediction_objective(my_params, data=manual_data, alpha=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 10 iterations\n"
     ]
    }
   ],
   "source": [
    "params = train(manual_data, latent_prediction_objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective Cost/Loss: 2.612220840338469e-20\n",
      "Model reduction Matrix: [[-1.92 -0.51  1.21  0.51]]\n",
      "Dynamics Matrix: [[0.]] , [[-0.71 26.03]]\n",
      "Cost Matrix: [[1.97]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Objective Cost/Loss:\", latent_prediction_objective(params, manual_data, alpha=0.5))\n",
    "A, B, C, D = params_to_matrices(params)\n",
    "print(\"Model reduction Matrix:\", A)\n",
    "print(\"Dynamics Matrix:\", B, ',', C)\n",
    "print(\"Cost Matrix:\", D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yup, still works. Although this data is not realistic to the motion of the links. This just shows that if we add a distractor variable which does not help explain the cost, we can still \"ignore it\". Specifically, the B matrix (just a real number here) is still 0 and the y components of the model reduction can be arbitrary values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now with some data from Gazebo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = load_gazebo_data(\"/home/pmitrano/catkin_ws/src/link_bot/link_bot_teleop/data/fwd_1.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_gz_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7b228dd73b55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_gz_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_gz_data' is not defined"
     ]
    }
   ],
   "source": [
    "plot_gz_data(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See how our previous model reduction transfers\n",
    "\n",
    "To use the same models, the dimensionality of the input data must be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective Cost/Loss transfering to more complicated simulation: 1.3686914577862098e-06\n"
     ]
    }
   ],
   "source": [
    "print(\"Objective Cost/Loss transfering to more complicated simulation:\",\n",
    "      latent_prediction_objective(params, new_data, alpha=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show that our hand-designed parameters still work well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective Cost/Loss: 2.6472522881450943e-05\n"
     ]
    }
   ],
   "source": [
    "my_params = np.array([1, 0, 0, 0, 0, 0.1, 0, 1])\n",
    "print(\"Objective Cost/Loss:\", latent_prediction_objective(my_params, new_data, alpha=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to optimize on our new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 32 iterations\n"
     ]
    }
   ],
   "source": [
    "params = train(new_data, latent_prediction_objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective Cost/Loss: 1.2712319581078583e-05\n",
      "Model reduction Matrix: [[  0.25 189.48  -0.32 421.56]]\n",
      "Dynamics Matrix: [[0.]] , [[-0.01 -0.01]]\n",
      "Cost Matrix: [[212.84]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Objective Cost/Loss:\", latent_prediction_objective(params, new_data, alpha=0.5))\n",
    "A, B, C, D = params_to_matrices(params)\n",
    "print(\"Model reduction Matrix:\", A)\n",
    "print(\"Dynamics Matrix:\", B, ',', C)\n",
    "print(\"Cost Matrix:\", D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on Gazebo data may not be quite as good\n",
    "\n",
    "So there are two issues here. First, the control equation is not actually linear anymore. This is because in this gazebo data the links are accelerating, so their delta x position cannot be computed as $v_x*\\Delta t$ anymore. This would explain why the hand specified parameters do not give as small of a loss (1e-5 versus 1e-20)\n",
    "\n",
    "There may be another issue which is that the optimizer finds are not as good as the manual parameters anymore. However, I cannot confirm whether this issue is statistically significant."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
